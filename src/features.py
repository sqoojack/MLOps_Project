import pandas as pd
import yaml
import os
import json
import random  # æ–°å¢å¼•ç”¨
from datasets import load_dataset
from sklearn.model_selection import train_test_split

with open("params.yaml") as f:
    params = yaml.safe_load(f)

def get_random_price():
    """ç”Ÿæˆéš¨æ©Ÿåƒ¹æ ¼ (æ•´åˆè‡ª fix_prices.py)"""
    return f"${round(random.uniform(50, 200), 2)}"

def process_data():
    print("ğŸš€ Loading Amazon Reviews 2023 from Hugging Face...")
    
    # æŒ‡å®šé¡åˆ¥
    category = "All_Beauty" 
    
    # 1. è¼‰å…¥è©•è«–æ•¸æ“š
    dataset = load_dataset("McAuley-Lab/Amazon-Reviews-2023", f"raw_review_{category}", split="full", trust_remote_code=True)
    df = dataset.to_pandas()
    
    # ç°¡å–®éæ¿¾èˆ‡é‡æ–°å‘½å
    df = df[['user_id', 'parent_asin', 'timestamp']]
    df.columns = ['visitorid', 'itemid', 'timestamp']
    
    # 2. å»ºç«‹ Item Map
    unique_items = df['itemid'].unique()
    item_map = {asin: i+1 for i, asin in enumerate(unique_items)}
    
    # store item_map
    item_map_dir = os.path.dirname(params['data']['item_map_path'])
    if item_map_dir:  
        os.makedirs(item_map_dir, exist_ok=True)
        
    with open(params['data']['item_map_path'], 'w') as f:
        json.dump(item_map, f)
    
    df['item_idx'] = df['itemid'].map(item_map)
    
    # 3. è¼‰å…¥ Metadata ä¸¦åŒæ™‚è™•ç†åƒ¹æ ¼ (Merge fix_prices logic)
    print("ğŸ“¦ Loading Metadata and Fixing Prices...")
    meta_dataset = load_dataset("McAuley-Lab/Amazon-Reviews-2023", f"raw_meta_{category}", split="full", trust_remote_code=True)
    meta_df = meta_dataset.to_pandas()
    
    metadata_map = {}
    fixed_price_count = 0
    
    for _, row in meta_df.iterrows():
        asin = row['parent_asin']
        if asin in item_map:
            # å–å¾—åœ–ç‰‡
            img_url = row['images']['large'][0] if row['images'] and len(row['images']['large']) > 0 else None
            
            # [æ•´åˆ] è™•ç†åƒ¹æ ¼é‚è¼¯
            raw_price = row.get('price', None)
            if raw_price is None or str(raw_price).strip() in ["None", "N/A", ""]:
                final_price = get_random_price()
                fixed_price_count += 1
            else:
                final_price = raw_price

            metadata_map[str(item_map[asin])] = {
                "name": row['title'],
                "image": img_url,
                "asin": asin,
                "price": final_price
            }

    # å„²å­˜ metadata
    metadata_dir = os.path.dirname(params['data']['metadata_path'])
    if metadata_dir:
        os.makedirs(metadata_dir, exist_ok=True)
    with open(params['data']['metadata_path'], 'w') as f:
        json.dump(metadata_map, f)
        
    print(f"âœ… Metadata processed. Fixed prices for {fixed_price_count} items missing price info.")

    # 4. æ’åºèˆ‡åˆ†å‰²
    df = df.sort_values(['visitorid', 'timestamp'])
    
    item_counts = df['item_idx'].value_counts()
    valid_items = item_counts[item_counts >= params['data']['min_item_count']].index
    df = df[df['item_idx'].isin(valid_items)]

    split_idx = int(len(df) * (1 - params['data']['test_size']))
    train_df = df.iloc[:split_idx].copy()
    test_df = df.iloc[split_idx:].copy()

    os.makedirs("data/processed", exist_ok=True)
    train_df.to_csv(params['data']['processed_train_path'], index=False)
    test_df.to_csv(params['data']['processed_test_path'], index=False)
    
    print(f"ğŸ‰ Data split done. Train: {len(train_df)}, Test: {len(test_df)}")

if __name__ == "__main__":
    process_data()